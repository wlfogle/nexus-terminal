import React, { useState, useEffect, useCallback, useRef } from 'react';\nimport { useSelector, useDispatch } from 'react-redux';\nimport { Eye, Search, Brain, Camera, BookOpen, Zap, AlertTriangle, CheckCircle } from 'lucide-react';\nimport { selectActiveTab, addAIMessage } from '../../store/slices/terminalTabSlice';\nimport { ragService } from '../../services/ragService';\nimport { visionService, ScreenAnalysis } from '../../services/visionService';\nimport { cn } from '../../lib/utils';\n\ninterface EnhancedAIAssistantProps {\n  className?: string;\n}\n\ninterface AICapability {\n  id: string;\n  name: string;\n  description: string;\n  icon: React.ElementType;\n  enabled: boolean;\n  status: 'ready' | 'loading' | 'error' | 'disabled';\n}\n\ninterface RAGContext {\n  query: string;\n  results: Array<{\n    content: string;\n    similarity: number;\n    type: string;\n    path?: string;\n  }>;\n  contextUsed: boolean;\n}\n\ninterface VisionContext {\n  hasScreenshot: boolean;\n  analysis?: ScreenAnalysis;\n  contextUsed: boolean;\n}\n\nconst EnhancedAIAssistant: React.FC<EnhancedAIAssistantProps> = ({ className }) => {\n  const dispatch = useDispatch();\n  const activeTab = useSelector(selectActiveTab);\n  const [message, setMessage] = useState('');\n  const [isLoading, setIsLoading] = useState(false);\n  const [capabilities, setCapabilities] = useState<AICapability[]>([\n    {\n      id: 'rag',\n      name: 'RAG Knowledge',\n      description: 'Semantic search across codebase and history',\n      icon: Brain,\n      enabled: false,\n      status: 'loading'\n    },\n    {\n      id: 'vision',\n      name: 'Computer Vision',\n      description: 'See and understand your screen',\n      icon: Eye,\n      enabled: false,\n      status: 'loading'\n    },\n    {\n      id: 'proactive',\n      name: 'Proactive Assistant',\n      description: 'Automatic suggestions based on context',\n      icon: Zap,\n      enabled: true,\n      status: 'ready'\n    },\n    {\n      id: 'documentation',\n      name: 'Smart Documentation',\n      description: 'Context-aware help and documentation',\n      icon: BookOpen,\n      enabled: true,\n      status: 'ready'\n    }\n  ]);\n  \n  const [ragContext, setRagContext] = useState<RAGContext>({ \n    query: '', \n    results: [], \n    contextUsed: false \n  });\n  \n  const [visionContext, setVisionContext] = useState<VisionContext>({ \n    hasScreenshot: false, \n    contextUsed: false \n  });\n  \n  const [showAdvancedOptions, setShowAdvancedOptions] = useState(false);\n  const [useScreenContext, setUseScreenContext] = useState(false);\n  const [useRAGContext, setUseRAGContext] = useState(true);\n  const messagesEndRef = useRef<HTMLDivElement>(null);\n\n  // Initialize AI capabilities\n  useEffect(() => {\n    const initializeCapabilities = async () => {\n      // Initialize RAG service\n      try {\n        await ragService.initialize();\n        setCapabilities(prev => prev.map(cap => \n          cap.id === 'rag' ? { ...cap, enabled: true, status: 'ready' } : cap\n        ));\n        \n        // Index current project if we have an active tab\n        if (activeTab?.workingDirectory) {\n          await ragService.indexCodebase(activeTab.workingDirectory);\n        }\n      } catch (error) {\n        console.warn('RAG service initialization failed:', error);\n        setCapabilities(prev => prev.map(cap => \n          cap.id === 'rag' ? { ...cap, status: 'error' } : cap\n        ));\n      }\n      \n      // Initialize Vision service\n      try {\n        await visionService.initialize();\n        setCapabilities(prev => prev.map(cap => \n          cap.id === 'vision' ? { ...cap, enabled: true, status: 'ready' } : cap\n        ));\n      } catch (error) {\n        console.warn('Vision service initialization failed:', error);\n        setCapabilities(prev => prev.map(cap => \n          cap.id === 'vision' ? { ...cap, status: 'error' } : cap\n        ));\n      }\n    };\n    \n    initializeCapabilities();\n  }, [activeTab?.workingDirectory]);\n\n  // Auto-scroll to bottom when new messages arrive\n  useEffect(() => {\n    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });\n  }, [activeTab?.aiConversation]);\n\n  // Handle proactive suggestions based on screen changes\n  useEffect(() => {\n    if (!capabilities.find(c => c.id === 'vision')?.enabled) return;\n    \n    const handleScreenChange = (analysis: ScreenAnalysis) => {\n      // Auto-generate suggestions for errors\n      if (analysis.detectedContext.errorMessages && \n          analysis.detectedContext.errorMessages.length > 0) {\n        handleProactiveSuggestion(\n          `I noticed error messages on your screen: \"${analysis.detectedContext.errorMessages.join(', ')}\". Would you like help resolving these?`,\n          { analysis, type: 'error_detection' }\n        );\n      }\n      \n      // Suggest help for new terminal commands\n      if (analysis.detectedContext.windowType === 'terminal' && \n          analysis.detectedContext.terminalCommands) {\n        const recentCommand = analysis.detectedContext.terminalCommands[analysis.detectedContext.terminalCommands.length - 1];\n        if (recentCommand && recentCommand.includes('error') || recentCommand.includes('failed')) {\n          handleProactiveSuggestion(\n            `I see you might be having issues with \"${recentCommand}\". Need assistance?`,\n            { analysis, type: 'command_assistance' }\n          );\n        }\n      }\n    };\n    \n    // Start screen monitoring for proactive assistance\n    visionService.startScreenMonitoring(handleScreenChange, 10000);\n  }, [capabilities]);\n\n  const handleProactiveSuggestion = async (suggestion: string, context: any) => {\n    if (!activeTab) return;\n    \n    dispatch(addAIMessage({\n      tabId: activeTab.id,\n      message: {\n        role: 'assistant',\n        content: `ðŸ” **Proactive Suggestion**: ${suggestion}`,\n        timestamp: new Date(),\n        metadata: {\n          type: 'proactive_suggestion',\n          context,\n          capabilities_used: ['vision', 'proactive']\n        }\n      }\n    }));\n  };\n\n  const captureScreen = async () => {\n    try {\n      const capture = await visionService.captureScreen();\n      const analysis = await visionService.analyzeScreen(capture.id);\n      \n      setVisionContext({\n        hasScreenshot: true,\n        analysis,\n        contextUsed: false\n      });\n      \n      return analysis;\n    } catch (error) {\n      console.error('Failed to capture screen:', error);\n      throw error;\n    }\n  };\n\n  const performRAGSearch = async (query: string) => {\n    try {\n      const results = await ragService.search({\n        query,\n        maxResults: 5,\n        threshold: 0.6\n      });\n      \n      setRagContext({\n        query,\n        results: results.map(r => ({\n          content: r.document.content,\n          similarity: r.similarity,\n          type: r.document.metadata.type,\n          path: r.document.metadata.path\n        })),\n        contextUsed: false\n      });\n      \n      return results;\n    } catch (error) {\n      console.error('RAG search failed:', error);\n      return [];\n    }\n  };\n\n  const handleSendMessage = async () => {\n    if (!message.trim() || !activeTab) return;\n    \n    setIsLoading(true);\n    const userMessage = message;\n    setMessage('');\n    \n    try {\n      // Add user message\n      dispatch(addAIMessage({\n        tabId: activeTab.id,\n        message: {\n          role: 'user',\n          content: userMessage,\n          timestamp: new Date()\n        }\n      }));\n      \n      let contextualInfo = '';\n      const capabilitiesUsed: string[] = [];\n      \n      // Gather RAG context if enabled\n      if (useRAGContext && capabilities.find(c => c.id === 'rag')?.enabled) {\n        const ragResults = await performRAGSearch(userMessage);\n        if (ragResults.length > 0) {\n          contextualInfo += await ragService.getContextForPrompt(userMessage, activeTab.workingDirectory);\n          capabilitiesUsed.push('rag');\n        }\n      }\n      \n      // Gather vision context if enabled and requested\n      if (useScreenContext && capabilities.find(c => c.id === 'vision')?.enabled) {\n        try {\n          const screenHelp = await visionService.getContextualHelp();\n          contextualInfo += `\\n\\n## ðŸ‘ï¸ Screen Context:\\n${screenHelp}`;\n          capabilitiesUsed.push('vision');\n          setVisionContext(prev => ({ ...prev, contextUsed: true }));\n        } catch (error) {\n          console.warn('Failed to get screen context:', error);\n        }\n      }\n      \n      // Build enhanced prompt\n      const enhancedPrompt = `${contextualInfo}\\n\\n**User Query**: ${userMessage}\\n\\n**Current Context**:\\n- Working Directory: ${activeTab.workingDirectory}\\n- Shell: ${activeTab.shell}\\n- Recent Commands: ${activeTab.aiContext.recentCommands.slice(-3).join(', ')}`;\n      \n      // Send to AI with enhanced context\n      const response = await fetch('/api/ai/chat', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          messages: [\n            ...activeTab.aiConversation.slice(-10), // Include recent conversation\n            { role: 'user', content: enhancedPrompt }\n          ],\n          context: {\n            tabId: activeTab.id,\n            capabilities: capabilitiesUsed,\n            workingDirectory: activeTab.workingDirectory\n          }\n        }),\n      });\n      \n      if (!response.ok) {\n        throw new Error(`HTTP error! status: ${response.status}`);\n      }\n      \n      const aiResponse = await response.text();\n      \n      // Add AI response\n      dispatch(addAIMessage({\n        tabId: activeTab.id,\n        message: {\n          role: 'assistant',\n          content: aiResponse,\n          timestamp: new Date(),\n          metadata: {\n            capabilities_used: capabilitiesUsed,\n            context_length: contextualInfo.length,\n            rag_results: useRAGContext ? ragContext.results.length : 0,\n            vision_used: useScreenContext\n          }\n        }\n      }));\n      \n      // Mark contexts as used\n      if (useRAGContext) {\n        setRagContext(prev => ({ ...prev, contextUsed: true }));\n      }\n      \n    } catch (error) {\n      console.error('Failed to send message:', error);\n      \n      dispatch(addAIMessage({\n        tabId: activeTab.id,\n        message: {\n          role: 'assistant',\n          content: `âŒ Sorry, I encountered an error: ${error instanceof Error ? error.message : 'Unknown error'}`,\n          timestamp: new Date(),\n          metadata: { error: true }\n        }\n      }));\n    } finally {\n      setIsLoading(false);\n    }\n  };\n\n  const getCapabilityIcon = (capability: AICapability) => {\n    const Icon = capability.icon;\n    const statusColors = {\n      ready: 'text-green-500',\n      loading: 'text-yellow-500 animate-pulse',\n      error: 'text-red-500',\n      disabled: 'text-gray-400'\n    };\n    \n    return <Icon className={cn('w-4 h-4', statusColors[capability.status])} />;\n  };\n\n  const getCapabilityStatusIcon = (status: AICapability['status']) => {\n    switch (status) {\n      case 'ready':\n        return <CheckCircle className=\"w-3 h-3 text-green-500\" />;\n      case 'loading':\n        return <div className=\"w-3 h-3 rounded-full border-2 border-yellow-500 border-t-transparent animate-spin\" />;\n      case 'error':\n        return <AlertTriangle className=\"w-3 h-3 text-red-500\" />;\n      default:\n        return <div className=\"w-3 h-3 rounded-full bg-gray-400\" />;\n    }\n  };\n\n  if (!activeTab) {\n    return (\n      <div className={cn('flex items-center justify-center h-full text-gray-500', className)}>\n        <div className=\"text-center\">\n          <Brain className=\"w-12 h-12 mx-auto mb-4 opacity-50\" />\n          <p>No active terminal tab</p>\n          <p className=\"text-sm\">Create a tab to start using AI assistance</p>\n        </div>\n      </div>\n    );\n  }\n\n  return (\n    <div className={cn('flex flex-col h-full bg-gray-50 dark:bg-gray-900', className)}>\n      {/* AI Capabilities Header */}\n      <div className=\"flex-shrink-0 p-4 bg-white dark:bg-gray-800 border-b border-gray-200 dark:border-gray-700\">\n        <div className=\"flex items-center justify-between mb-3\">\n          <h3 className=\"font-semibold text-gray-900 dark:text-gray-100 flex items-center gap-2\">\n            <Brain className=\"w-5 h-5 text-blue-500\" />\n            Enhanced AI Assistant\n          </h3>\n          <button\n            onClick={() => setShowAdvancedOptions(!showAdvancedOptions)}\n            className=\"text-sm text-blue-600 hover:text-blue-700 dark:text-blue-400\"\n          >\n            {showAdvancedOptions ? 'Hide' : 'Show'} Options\n          </button>\n        </div>\n        \n        {/* Capabilities Status */}\n        <div className=\"grid grid-cols-2 gap-2 mb-3\">\n          {capabilities.map(capability => (\n            <div key={capability.id} className=\"flex items-center gap-2 text-sm\">\n              {getCapabilityIcon(capability)}\n              <span className={cn(\n                'flex-1 text-xs',\n                capability.enabled ? 'text-gray-700 dark:text-gray-300' : 'text-gray-400'\n              )}>\n                {capability.name}\n              </span>\n              {getCapabilityStatusIcon(capability.status)}\n            </div>\n          ))}\n        </div>\n        \n        {/* Advanced Options */}\n        {showAdvancedOptions && (\n          <div className=\"space-y-2 pt-3 border-t border-gray-200 dark:border-gray-600\">\n            <label className=\"flex items-center gap-2 text-sm\">\n              <input\n                type=\"checkbox\"\n                checked={useRAGContext}\n                onChange={(e) => setUseRAGContext(e.target.checked)}\n                disabled={!capabilities.find(c => c.id === 'rag')?.enabled}\n                className=\"rounded\"\n              />\n              <span>Use RAG context from codebase</span>\n            </label>\n            \n            <label className=\"flex items-center gap-2 text-sm\">\n              <input\n                type=\"checkbox\"\n                checked={useScreenContext}\n                onChange={(e) => setUseScreenContext(e.target.checked)}\n                disabled={!capabilities.find(c => c.id === 'vision')?.enabled}\n                className=\"rounded\"\n              />\n              <span>Include screen context</span>\n            </label>\n            \n            {capabilities.find(c => c.id === 'vision')?.enabled && (\n              <button\n                onClick={captureScreen}\n                className=\"flex items-center gap-2 text-sm text-blue-600 hover:text-blue-700 dark:text-blue-400\"\n              >\n                <Camera className=\"w-4 h-4\" />\n                Capture Screen Now\n              </button>\n            )}\n          </div>\n        )}\n        \n        {/* Context Indicators */}\n        <div className=\"flex gap-2 mt-2\">\n          {ragContext.results.length > 0 && (\n            <div className=\"flex items-center gap-1 text-xs bg-blue-100 dark:bg-blue-900 text-blue-700 dark:text-blue-300 px-2 py-1 rounded\">\n              <Search className=\"w-3 h-3\" />\n              {ragContext.results.length} RAG results\n            </div>\n          )}\n          \n          {visionContext.hasScreenshot && (\n            <div className=\"flex items-center gap-1 text-xs bg-purple-100 dark:bg-purple-900 text-purple-700 dark:text-purple-300 px-2 py-1 rounded\">\n              <Eye className=\"w-3 h-3\" />\n              Screen captured\n            </div>\n          )}\n        </div>\n      </div>\n      \n      {/* Conversation Area */}\n      <div className=\"flex-1 overflow-y-auto p-4 space-y-4\">\n        {activeTab.aiConversation.map((msg, index) => (\n          <div\n            key={index}\n            className={cn(\n              'flex',\n              msg.role === 'user' ? 'justify-end' : 'justify-start'\n            )}\n          >\n            <div\n              className={cn(\n                'max-w-[80%] px-4 py-2 rounded-lg',\n                msg.role === 'user'\n                  ? 'bg-blue-500 text-white'\n                  : 'bg-white dark:bg-gray-800 text-gray-900 dark:text-gray-100 border border-gray-200 dark:border-gray-700'\n              )}\n            >\n              <div className=\"whitespace-pre-wrap\">{msg.content}</div>\n              \n              {/* Metadata for AI messages */}\n              {msg.role === 'assistant' && msg.metadata && (\n                <div className=\"mt-2 pt-2 border-t border-gray-200 dark:border-gray-600 text-xs text-gray-500\">\n                  {msg.metadata.capabilities_used && (\n                    <div>Capabilities: {msg.metadata.capabilities_used.join(', ')}</div>\n                  )}\n                  {msg.metadata.rag_results > 0 && (\n                    <div>RAG results used: {msg.metadata.rag_results}</div>\n                  )}\n                  {msg.metadata.vision_used && (\n                    <div>Screen context included</div>\n                  )}\n                </div>\n              )}\n            </div>\n          </div>\n        ))}\n        \n        {isLoading && (\n          <div className=\"flex justify-start\">\n            <div className=\"bg-gray-200 dark:bg-gray-700 px-4 py-2 rounded-lg\">\n              <div className=\"flex items-center gap-2 text-gray-600 dark:text-gray-400\">\n                <div className=\"w-2 h-2 bg-current rounded-full animate-pulse\" />\n                <div className=\"w-2 h-2 bg-current rounded-full animate-pulse\" style={{ animationDelay: '0.2s' }} />\n                <div className=\"w-2 h-2 bg-current rounded-full animate-pulse\" style={{ animationDelay: '0.4s' }} />\n                <span className=\"text-sm ml-2\">AI is thinking...</span>\n              </div>\n            </div>\n          </div>\n        )}\n        <div ref={messagesEndRef} />\n      </div>\n      \n      {/* Input Area */}\n      <div className=\"flex-shrink-0 p-4 bg-white dark:bg-gray-800 border-t border-gray-200 dark:border-gray-700\">\n        <div className=\"flex gap-2\">\n          <input\n            type=\"text\"\n            value={message}\n            onChange={(e) => setMessage(e.target.value)}\n            onKeyPress={(e) => e.key === 'Enter' && !e.shiftKey && handleSendMessage()}\n            placeholder=\"Ask me anything about your code, terminal, or what you see on screen...\"\n            className=\"flex-1 px-4 py-2 border border-gray-300 dark:border-gray-600 rounded-lg focus:ring-2 focus:ring-blue-500 focus:border-transparent bg-white dark:bg-gray-900 text-gray-900 dark:text-gray-100\"\n            disabled={isLoading}\n          />\n          <button\n            onClick={handleSendMessage}\n            disabled={isLoading || !message.trim()}\n            className=\"px-6 py-2 bg-blue-500 hover:bg-blue-600 disabled:bg-gray-400 text-white rounded-lg font-medium transition-colors\"\n          >\n            Send\n          </button>\n        </div>\n      </div>\n    </div>\n  );\n};\n\nexport default EnhancedAIAssistant;"
